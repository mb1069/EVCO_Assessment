

@ARTICLE{Shapiro1965-my,
  title     = "An Analysis of Variance Test for Normality (Complete Samples)",
  author    = "Shapiro, S S and Wilk, M B",
  journal   = "Biometrika",
  publisher = "[Oxford University Press, Biometrika Trust]",
  volume    =  52,
  number    = "3/4",
  pages     = "591--611",
  year      =  1965
}


@INPROCEEDINGS{Luke2001-ix,
  title     = "A Survey and Comparison of Tree Generation Algorithms",
  booktitle = "Proceedings of the 3rd Annual Conference on Genetic and
               Evolutionary Computation",
  author    = "Luke, Sean and Panait, Liviu",
  publisher = "Morgan Kaufmann Publishers Inc.",
  pages     = "81--88",
  series    = "GECCO'01",
  year      =  2001,
  address   = "San Francisco, CA, USA"
}


@INPROCEEDINGS{Xie2007-zf,
  title     = "An analysis of depth of crossover points in tree-based Genetic
               Programming",
  booktitle = "2007 {IEEE} Congress on Evolutionary Computation",
  author    = "Xie, Huayang and Zhang, Mengjie and Andreae, P",
  abstract  = "The standard crossover operator in tree-based genetic
               programming (GP) is problematic in that it is most often
               destructive. Selecting crossover points with an implicit bias
               towards the leaves of a program tree aggravates its
               destructiveness and causes the code bloat problem in GP.
               Therefore, a common view has been developed that adjusting the
               depth of crossover points to eliminate the bias can improve GP
               performance, and many attempts have been made to create
               effective crossover operators according to this view. As there
               are a large number of possible depth-control strategies, it is
               very difficult to identify the strategy that provides the most
               significant improvement in performance. This paper explores
               depth-control strategies by analysing the depth of crossover
               points in evolutionary process logs of five different GP systems
               on problems in three different domains. It concludes that
               controlling the depth of crossover points is an evolutionary
               stage dependent and problem dependent task, and obtaining a
               significant performance improvement is not trivial.",
  pages     = "4561--4568",
  year      =  2007,
  keywords  = "genetic algorithms;trees (mathematics);code bloat
               problem;crossover operators;depth-control
               strategies;evolutionary process logs;performance
               improvement;problem dependent task;tree-based genetic
               programming;Code standards;Genetic programming;Indium tin
               oxide;Random variables;Wheels"
}



@BOOK{Koza1992-zm,
  title     = "Genetic Programming: On the Programming of Computers by Means of
               Natural Selection",
  author    = "Koza, John R",
  publisher = "MIT Press",
  year      =  1992,
  address   = "Cambridge, MA, USA"
}



@INPROCEEDINGS{Hauptman2005-zg,
  title      = "{GP-EndChess}: Using Genetic Programming to Evolve Chess
                Endgame Players",
  booktitle  = "Genetic Programming",
  author     = "Hauptman, Ami and Sipper, Moshe",
  editor     = "Keijzer, Maarten and Tettamanzi, Andrea and Collet, Pierre and
                van Hemert, Jano and Tomassini, Marco",
  abstract   = "We apply genetic programming to the evolution of strategies for
                playing chess endgames. Our evolved programs are able to draw
                or win against an expert human-based strategy, and draw against
                CRAFTY---a world-class chess program, which finished second in
                the 2004 Computer Chess Championship.",
  publisher  = "Springer Berlin Heidelberg",
  pages      = "120--131",
  series     = "Lecture Notes in Computer Science",
  month      =  "30~" # mar,
  year       =  2005,
  language   = "en",
  conference = "European Conference on Genetic Programming"
}


@ARTICLE{Back2000-og,
  title    = "Evolutionary Computation 1 (Basic Algorithms and Operators)",
  author   = "{B{\"a}ck} and and Fogel, T and and Michalewicz, D B",
  abstract = "Evolutionary Computation 1 (Basic Algorithms and Operators) on
              ResearchGate, the professional network for scientists.",
  month    =  "1~" # jan,
  year     =  2000
}



@MISC{noauthor_undated-bi,
  title        = "8.3. collections --- Container datatypes --- Python 3.6.0
                  documentation",
  howpublished = "\url{https://docs.python.org/3/library/collections.html}",
  note         = "Accessed: 2017-1-23"
}


@BOOK{Timm2002-lo,
  title     = "Applied Multivariate Analysis:",
  editor    = "Timm, Neil H",
  publisher = "Springer New York",
  series    = "Springer Texts in Statistics",
  year      =  2002
}



@ARTICLE{Richards1998-si,
  title     = "Evolving Neural Networks to Play Go",
  author    = "Richards, Norman and Moriarty, David E and Miikkulainen, Risto",
  abstract  = "Go is a difficult game for computers to master, and the best go
               programs are still weaker than the average human player. Since
               the traditional game playing techniques have proven inadequate,
               new approaches to computer go need to be studied. This paper
               presents a new approach to learning to play go. The SANE
               (Symbiotic, Adaptive Neuro-Evolution) method was used to evolve
               networks capable of playing go on small boards with no
               pre-programmed go knowledge. On a 9 $\times$ 9 go board,
               networks that were able to defeat a simple computer opponent
               were evolved within a few hundred generations. Most
               significantly, the networks exhibited several aspects of general
               go playing, which suggests the approach could scale up well.",
  journal   = "Applied Intelligence",
  publisher = "Kluwer Academic Publishers",
  volume    =  8,
  number    =  1,
  pages     = "85--96",
  month     =  "1~" # jan,
  year      =  1998,
  language  = "en"
}


@ARTICLE{Brain2011-pz,
  title       = "Optimization of a genetic algorithm for searching molecular
                 conformer space",
  author      = "Brain, Zoe E and Addicoat, Matthew A",
  affiliation = "Department of Computer Science, Australian National
                 University, Canberra, ACT 0200, Australia.",
  abstract    = "We present two sets of tunings that are broadly applicable to
                 conformer searches of isolated molecules using a genetic
                 algorithm (GA). In order to find the most efficient tunings
                 for the GA, a second GA--a meta-genetic algorithm--was used to
                 tune the first genetic algorithm to reliably find the already
                 known a priori correct answer with minimum computational
                 resources. It is shown that these tunings are appropriate for
                 a variety of molecules with different characteristics, and
                 most importantly that the tunings are independent of the
                 underlying model chemistry but that the tunings for rigid and
                 relaxed surfaces differ slightly. It is shown that for the
                 problem of molecular conformational search, the most efficient
                 GA actually reduces to an evolutionary algorithm.",
  journal     = "J. Chem. Phys.",
  volume      =  135,
  number      =  17,
  pages       = "174106",
  month       =  "7~" # nov,
  year        =  2011,
  language    = "en"
}


@INPROCEEDINGS{Fogel1993-qp,
  title     = "Using evolutionary programing to create neural networks that are
               capable of playing tic-tac-toe",
  booktitle = "{IEEE} International Conference on Neural Networks",
  author    = "Fogel, D B",
  abstract  = "The use of evolutionary programming for adapting the design and
               weights of a multi-layer feedforward perceptron in the context
               of machine learning is described. Specifically, it is desired to
               evolve the structure and weights of a single hidden layer
               perceptron such that it can achieve a high level of play in the
               game tic-tac-toe without the use of heuristics or credit
               assignment algorithms. Conclusions from the experiments are
               offered regarding the relative importance of specific mutation
               operations, the necessity for credit assignment procedures, and
               the efficiency and effectiveness of evolutionary search",
  pages     = "875--880 vol.2",
  year      =  1993,
  keywords  = "feedforward neural nets;learning (artificial
               intelligence);stochastic programming;credit assignment
               algorithms;credit assignment procedures;evolutionary
               programing;evolutionary search;heuristics;machine
               learning;multi-layer feedforward perceptron;mutation
               operations;neural networks;single hidden layer
               perceptron;tic-tac-toe;Evolution (biology);Genetic
               algorithms;Genetic mutations;Genetic programming;Intelligent
               systems;Learning systems;Machine intelligence;Machine
               learning;Machine learning algorithms;Neural networks"
}


@ARTICLE{Hausknecht2014-uc,
  title    = "A Neuroevolution Approach to General Atari Game Playing",
  author   = "Hausknecht, M and Lehman, J and Miikkulainen, R and Stone, P",
  abstract = "This paper addresses the challenge of learning to play many
              different video games with little domain-specific knowledge.
              Specifically, it introduces a neuroevolution approach to general
              Atari 2600 game playing. Four neuroevolution algorithms were
              paired with three different state representations and evaluated
              on a set of 61 Atari games. The neuroevolution agents represent
              different points along the spectrum of algorithmic sophistication
              - including weight evolution on topologically fixed neural
              networks (conventional neuroevolution), covariance matrix
              adaptation evolution strategy (CMA-ES), neuroevolution of
              augmenting topologies (NEAT), and indirect network encoding
              (HyperNEAT). State representations include an object
              representation of the game screen, the raw pixels of the game
              screen, and seeded noise (a comparative baseline). Results
              indicate that direct-encoding methods work best on compact state
              representations while indirect-encoding methods (i.e., HyperNEAT)
              allow scaling to higher dimensional representations (i.e., the
              raw game screen). Previous approaches based on
              temporal-difference (TD) learning had trouble dealing with the
              large state spaces and sparse reward gradients often found in
              Atari games. Neuroevolution ameliorates these problems and
              evolved policies achieve state-of-the-art results, even
              surpassing human high scores on three games. These results
              suggest that neuroevolution is a promising approach to general
              video game playing (GVGP).",
  journal  = "IEEE Trans. Comput. Intell. AI Games",
  volume   =  6,
  number   =  4,
  pages    = "355--366",
  month    =  dec,
  year     =  2014,
  keywords = "computer games;covariance matrices;genetic algorithms;learning
              (artificial intelligence);multi-agent systems;neural
              nets;CMA-ES;GVGP;HyperNEAT;TD learning;algorithmic
              sophistication;compact state representation;conventional
              neuroevolution;covariance matrix adaptation evolution
              strategy;domain-specific knowledge;general Atari 2600 game
              playing;general video game playing;higher dimensional
              representation;indirect network encoding;indirect-encoding
              method;neuroevolution agents;neuroevolution
              algorithm;neuroevolution approach;neuroevolution of augmenting
              topology;object representation;raw game screen;sparse reward
              gradient;state representations;state spaces;temporal-difference
              learning;video games;weight evolution;Algorithm design and
              analysis;Artificial neural networks;Encoding;Games;Network
              topology;Topology;Algorithms;artificial neural
              networks;evolutionary computation;genetic algorithms;neural
              networks"
}


@INPROCEEDINGS{Michael_ONeill1999-zi,
  title     = "Evolving Multi-line Compilable {C} Programs",
  booktitle = "In Proceedings of the Second European Workshop on Genetic
               Programming",
  author    = "Michael O'Neill, Conor Ryan",
  abstract  = "CiteSeerX - Document Details (Isaac Councill, Lee Giles, Pradeep
               Teregowda): We describe a Genetic Algorithm called Grammatical
               Evolution (GE) that can evolve complete programs in an arbitrary
               language using a variable length linear genome. The binary
               genome determines which production rules in a Backus Naur Form
               grammar definition are used in a genotype to phenotype mapping
               process to a program. Expressions and programs of arbitrary
               complexity may be evolved using this system. Since first
               describing this system, GE has been applied to other problem
               domains, and during this time GE has undergone some evolution.
               This paper serves to report these changes, and also describes
               how we evolved multi-line C-code to solve a version of the Santa
               Fe Ant Trail. The results obtained are then compared to results
               produced by Genetic Programming, and it is found that GE
               outperforms GP on this problem.",
  year      =  1999
}



@InProceedings{ryan:1998:geepal,
  author =       "Conor Ryan and J. J. Collins and Michael O'Neill",
  title =        "Grammatical Evolution: Evolving Programs for an
                 Arbitrary Language",
  booktitle =    "Proceedings of the First European Workshop on Genetic
                 Programming",
  year =         "1998",
  editor =       "Wolfgang Banzhaf and Riccardo Poli and 
                 Marc Schoenauer and Terence C. Fogarty",
  volume =       "1391",
  series =       "LNCS",
  pages =        "83--96",
  address =      "Paris",
  publisher_address = "Berlin",
  month =        "14-15 " # apr,
  publisher =    "Springer-Verlag",
  keywords =     "genetic algorithms, genetic programming, grammatical
                 evolution",
  ISBN =         "3-540-64360-5",
  URL =          "http://www.lania.mx/~ccoello/eurogp98.ps.gz",
  URL =          "http://citeseer.ist.psu.edu/ryan98grammatical.html",
  doi =          "doi:10.1007/BFb0055930",
  size =         "14 pages",
  abstract =     "We describe a Genetic Algorithm that can evolve
                 complete programs. Using a variable length linear
                 genome to govern how a Backus Naur Form grammar
                 definition is mapped to a program, expressions and
                 programs of arbitrary complexity may be evolved. Other
                 automatic programming methods are described, before our
                 system, Grammatical Evolution, is applied to a symbolic
                 regression problem.",
  notes =        "EuroGP'98",
  affiliation =  "University of Limerick Dept. Of Computer Science and
                 Information Systems Ireland Ireland",
}
@BOOK{Chen2012-ei,
  title     = "Genetic Algorithms and Genetic Programming in Computational
               Finance",
  author    = "Chen, Shu-Heng",
  abstract  = "After a decade of development, genetic algorithms and genetic
               programming have become a widely accepted toolkit for
               computational finance. Genetic Algorithms and Genetic
               Programming in Computational Finance is a pioneering volume
               devoted entirely to a systematic and comprehensive review of
               this subject. Chapters cover various areas of computational
               finance, including financial forecasting, trading strategies
               development, cash flow management, option pricing, portfolio
               management, volatility modeling, arbitraging, and agent-based
               simulations of artificial stock markets. Two tutorial chapters
               are also included to help readers quickly grasp the essence of
               these tools. Finally, a menu-driven software program, Simple GP,
               accompanies the volume, which will enable readers without a
               strong programming background to gain hands-on experience in
               dealing with much of the technical material introduced in this
               work.",
  publisher = "Springer Science \& Business Media",
  month     =  "6~" # dec,
  year      =  2012,
  language  = "en"
}


@INPROCEEDINGS{Cramer_undated-bj,
  title           = "A Representation for the Adaptive Generation of Simple
                     Sequential Programs",
  booktitle       = "{PROCEEDINGS} {OF} {AN} {INTERNATIONAL} {CONFERENCE} {ON}
                     {GENETIC} {ALGORITHMS} {AND} {THEIR} {APPLICATIONS}",
  author          = "Cramer, Nichael Lynn",
  editor          = "Grefenstette, John J",
  publisher       = "U.S. Navy Center for Applied Research in Artificial
                     Intelligence",
  pages           = "183--187",
  institution     = "Texas Instruments Inc.",
  conference      = "Carnegie-Mellon University"
}


% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@BOOK{Goggin2010-ao,
  title     = "Global Mobile Media",
  author    = "Goggin, Gerard",
  abstract  = "Gerard Goggin has produced an incisive and penetrating overview
               of the world according to mobiles. Covering sight, sound and
               status, plus a host of other issues, he provides a provocative
               analysis of how mobile communication gadgets come to play such a
               prominent role in our lives. Any scholar of New Media will want
               to read this book -- James Katz, Department of Communication,
               Rutgers University, USA With billions of users worldwide, the
               cell phone is not only a successful communications technology;
               it is also key to the future of media. Global Mobile Media
               offers an overview of the complex topic of mobile media, looking
               at the emerging industry structures, new media economies, mobile
               media cultures and network politics of cell phones as they move
               centre-stage in media industries. The development, adoption and
               significance of cell phones for society and culture have been
               registered in a growing body of work. Where existing books have
               focused on communication, and on the social and cultural aspects
               of mobile media, Global Mobile Media looks at the media
               dimensions. Goggin provides a pioneering yet measured evaluation
               of how cell phone corporations, media interests, users and
               policy makers are together shaping a new media dispensation.
               Global Mobile Media successfully places new mobile media
               historically, socially and culturally in a wider field of
               portable media technologies through extensive case studies,
               including: the rise of smartphones, with a detailed discussion
               of the Apple iPhone and how it has catalysed a new phase in
               convergent media, audiences and innovation the new agenda in
               cultural politics and media policy, featuring topics such as
               iPhone apps and control, mobile commons, and open mobile
               networks a succinct map of the political economy of mobile
               media, identifying key players, patterns of ownership and
               control, institutions, and issues a critical account of cell
               phones’ involvement in and contribution to much-discussed new
               forms of production and consumption, such as user-generated
               content, p2p networks, open and free source software networks an
               anatomy of how cell phones relate to other online media,
               particularly the Internet and wireless technologies. Global
               Mobile Media is an engaging, accessible text which will be of
               immense interest to upper-level undergraduates, postgraduates
               and researchers in Communication Studies, Cultural Studies and
               Media Studies, as well as those taking New Media courses.",
  publisher = "Taylor \& Francis",
  month     =  "14~" # oct,
  year      =  2010,
  language  = "en"
}


@inproceedings{deap,
 author = {De Rainville, Fran\c{c}ois-Michel and Fortin, F{\'e}lix-Antoine and Gardner, Marc-Andr{\'e} and Parizeau, Marc and Gagn{\'e}, Christian},
 title = {DEAP: A Python Framework for Evolutionary Algorithms},
 booktitle = {Proceedings of the 14th Annual Conference Companion on Genetic and Evolutionary Computation},
 series = {GECCO '12},
 year = {2012},
 isbn = {978-1-4503-1178-6},
 location = {Philadelphia, Pennsylvania, USA},
 pages = {85--92},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/2330784.2330799},
 doi = {10.1145/2330784.2330799},
 acmid = {2330799},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {parallel evolutionary algorithms, software tools},
} 



@INPROCEEDINGS{Thaker2015-tn,
  title     = "Evolutionary computation in artificial board game playing
               through genetic weight evolution",
  booktitle = "2015 International Conference on Emerging Trends in Networks and
               Computer Communications ({ETNCC})",
  author    = "Thaker, C S and Jat, D S and Xoagub, A J",
  abstract  = "Artificial Intelligence researchers have witnessed substantial
               implementation of evolutionary computation in test-bed
               application domain like board games to evolve game playing
               programs. A genetic algorithm is a methodology to ``instill''
               and ``tune'' deterministic board game playing computer program.
               Evolutionary computation aims to solve problems that have very
               high search complexity and critical decision complexity. Game
               playing programs aims to play better by exploiting various
               possible moves by associating them with their ``goodness'' based
               on their weight values. These weights are given to specific disc
               positions squares according to board game feature based
               positional prominence. The weights are genetically evolved to
               arrive at move making decision. This paper focuses the
               application of disc set weight evolving through genetic
               operators induced for the Game of Othello.",
  pages     = "62--66",
  month     =  may,
  year      =  2015,
  keywords  = "artificial intelligence;computer games;genetic algorithms;Game
               of Othello;artificial board game;artificial
               intelligence;decision making;deterministic board game playing
               computer program;disc set weight;evolutionary computation;game
               feature based positional prominence;game playing
               programs;genetic algorithm;genetic weight
               evolution;Boards;Evolutionary computation;Games;Genetic
               algorithms;Genetics;Sociology;Statistics;artificial
               intelligence;board game;evaluation function;game of
               othello;genetic algorithms"
}

@INPROCEEDINGS{Jia2015-jk,
  title     = "A strongly typed {GP-based} video game player",
  booktitle = "2015 {IEEE} Conference on Computational Intelligence and Games
               ({CIG})",
  author    = "Jia, B and Ebner, M",
  abstract  = "This paper attempts to evolve a general video game player, i.e.
               an agent which is able to learn to play many different video
               games with little domain knowledge. Our project uses strongly
               typed genetic programming as a learning algorithm. Three simple
               hand-crafted features are chosen to represent the game state.
               Each feature is a vector which consists of the position and
               orientation of each game object that is visible on the screen.
               These feature vectors are handed to the learning algorithm which
               will output the action the game player will take next. Game
               knowledge and feature vectors are acquired by processing screen
               grabs from the game. Three different video games are used to
               test the algorithm. Experiments show that our algorithm is able
               to find solutions to play all these three games efficiently.",
  pages     = "299--305",
  month     =  aug,
  year      =  2015,
  keywords  = "computer games;genetic algorithms;learning (artificial
               intelligence);GP-based video game player;domain
               knowledge;feature vector;game knowledge;game object;game
               state;general video game player;genetic programming;hand-crafted
               feature;learning algorithm;screen grab;Avatars;Engines;Euclidean
               distance;Games;Genetic programming;Missiles;Monte Carlo methods"
}

@ARTICLE{Martinez-Arellano2016-gb,
  title    = "Creating {AI} Characters for Fighting Games using Genetic
              Programming",
  author   = "Martinez-Arellano, G and Cant, R and Woods, D",
  abstract = "This paper proposes a character generation approach for the
              M.U.G.E.N. fighting game that can create engaging AI characters
              using a computationally cheap process without the intervention of
              the expert developer. The approach uses a Genetic Programming
              algorithm that refines randomly generated character strategies
              into better ones using tournament selection. The generated AI
              characters were tested by twenty-seven human players and were
              rated according to results, perceived difficulty and how engaging
              the gameplay was. The main advantages of this procedure are that
              no prior knowledge of how to code the strategies of the AI
              character is needed and there is no need to interact with the
              internal code of the game. In addition, the procedure is capable
              of creating a wide diversity of players with different strategic
              skills, which could be potentially used as a starting point to a
              further adaptive process.",
  journal  = "IEEE Trans. Comput. Intell. AI Games",
  volume   = "PP",
  number   =  99,
  pages    = "1--1",
  year     =  2016,
  keywords = "Adaptation models;Games;Genetic algorithms;Genetic
              programming;Learning (artificial intelligence);Real-time
              systems;AI;Genetic programming;character;fighting games"
}

@INPROCEEDINGS{Wittkamp2006-cb,
  title     = "Evolving Adaptive Play for the Game of Spoof Using Genetic
               Programming",
  booktitle = "2006 {IEEE} Symposium on Computational Intelligence and Games",
  author    = "Wittkamp, M and Barone, L",
  abstract  = "Many games require opponent modelling for optimal performance.
               The implicit learning and adaptive nature of evolutionary
               computation techniques offer a natural way to develop and
               explore models of an opponent's strategy without significant
               overhead. In this paper, we propose the use of genetic
               programming to play the game of Spoof, a simple guessing game of
               imperfect information. We discuss the technical details needed
               to equip a computer to play the game and report on experiments
               using this approach that demonstrate emergent adaptive
               behaviour. We further show that specialisation via adaptation is
               crucial to maximise winnings and that no general strategy will
               suffice against all opponents",
  pages     = "164--172",
  month     =  may,
  year      =  2006,
  keywords  = "computer games;genetic algorithms;Spoof;adaptive
               play;evolutionary computation;genetic programming;guessing
               game;imperfect information games;Combinatorial
               mathematics;Computer science;Evolutionary
               computation;Explosions;Genetic mutations;Genetic
               programming;Minimax techniques;Predictive models;Software
               engineering;Working environment noise;Genetic
               Programming;Imperfect Information Games;Opponent Modelling;Spoof"
}

@INPROCEEDINGS{Wittkamp2007-hb,
  title     = "A Comparison of Genetic Programming and Look-up Table Learning
               for the Game of Spoof",
  booktitle = "2007 {IEEE} Symposium on Computational Intelligence and Games",
  author    = "Wittkamp, M and Barone, L and While, L",
  abstract  = "Many games require opponent modeling for optimal performance.
               The implicit learning and adaptive nature of evolutionary
               computation techniques offer a natural way to develop and
               explore models of an opponent's strategy without significant
               overhead. In this paper, we compare two learning techniques for
               strategy development in the game of Spoof, a simple guessing
               game of imperfect information. We compare a genetic programming
               approach with a look-up table based approach, contrasting the
               performance of each in different scenarios of the game. Results
               show both approaches have their advantages, but that the genetic
               programming approach achieves better performance in scenarios
               with little public information. We also trial both approaches
               against opponents who vary their strategy; results showing that
               the genetic programming approach is better able to respond to
               strategy changes than the look-up table based approach",
  pages     = "63--71",
  month     =  apr,
  year      =  2007,
  keywords  = "game theory;genetic algorithms;learning (artificial
               intelligence);table lookup;Spoof game;evolutionary
               computation;genetic programming;guessing game;imperfect
               information games;implicit learning;look-up table
               learning;opponent modeling;optimal performance;strategy
               development;Application software;Combinatorial
               mathematics;Computational intelligence;Computer
               science;Evolutionary computation;Explosions;Genetic
               programming;Predictive models;Software engineering;Table
               lookup;Genetic Programming;Imperfect Information Games;Look-up
               Table;Opponent Modeling;Spoof"
}

@INPROCEEDINGS{Alhejali2013-cl,
  title     = "Using genetic programming to evolve heuristics for a Monte Carlo
               Tree Search Ms {Pac-Man} agent",
  booktitle = "2013 {IEEE} Conference on Computational Inteligence in Games
               ({CIG})",
  author    = "Alhejali, A M and Lucas, S M",
  abstract  = "Ms Pac-Man is one of the most challenging test beds in game
               artificial intelligence (AI). Genetic programming and Monte
               Carlo Tree Search (MCTS) have already been successful applied to
               several games including Pac-Man. In this paper, we use Monte
               Carlo Tree Search to create a Ms Pac-Man playing agent before
               using genetic programming to enhance its performance by evolving
               a new default policy to replace the random agent used in the
               simulations. The new agent with the evolved default policy was
               able to achieve an 18\% increase on its average score over the
               agent with random default policy.",
  pages     = "1--8",
  month     =  aug,
  year      =  2013,
  keywords  = "Monte Carlo methods;artificial intelligence;computer
               games;genetic algorithms;tree searching;Al;MCTS;Monte Carlo tree
               search Ms Pac-Man agent;evolved default policy;game artificial
               intelligence;genetic programming;random agent;random default
               policy;Equations;Games;Genetic programming;Mathematical
               model;Monte Carlo methods;Sociology;Monte Carlo Tree
               Search;Pac-Man;genetic programming"
}

@MISC{Ehlis2000-sz,
  title        = "Application of Genetic Programming to the Snake Game -
                  Artificial Intelligence - Articles - Articles - {GameDev.net}",
  booktitle    = "gamedev.net",
  author       = "Ehlis, Tobin",
  abstract     = "This paper describes the evolution of a genetic program to
                  optimize a problem featuring task prioritization in a
                  dynamic, randomly updated environment. The specific problem
                  approached is the ``snake game'' in which a snake confined to
                  a rectangular board attempts to avoid the walls and its own
                  body while eating pieces of food. The problem is particularly
                  interesting because as the snake eats the food, its body
                  grows, causing the space through which the snake can navigate
                  to become more confined. Furthermore, with each piece of food
                  eaten, a new piece of food is generated in a random location
                  in the playing field, adding an element of uncertainty to the
                  program. This paper will focus on the development and
                  analysis of a successful function set that will allow the
                  evolution of a genetic program that causes the snake to eat
                  the maximum possible pieces of food.",
  month        =  "9~" # aug,
  year         =  2000,
  howpublished = "\url{https://www.gamedev.net/resources/_/technical/artificial-intelligence/application-of-genetic-programming-to-the-snake-r1175}",
  note         = "Accessed: 2017-1-16"
}


@ARTICLE{Benbassat2014-sj,
  title    = "{EvoMCTS}: A Scalable Approach for General Game Learning",
  author   = "Benbassat, A and Sipper, M",
  abstract = "In this paper, we present the application of genetic programming
              as a generic game learning approach to zero-sum, deterministic,
              full-knowledge board games by evolving board-state evaluation
              functions to be used in conjunction with Monte Carlo tree search
              (MCTS). Our method involves evolving board-evaluation functions
              that are then used to guide the MCTS playout strategy. We examine
              several variants of Reversi, Dodgem, and Hex using strongly typed
              genetic programming, explicitly defined introns, and a selective
              directional crossover method. Our results show a proficiency that
              surpasses that of baseline handcrafted players using equal and in
              some cases greater amounts of search, with little domain
              knowledge and no expert domain knowledge. Moreover, our results
              exhibit scalability.",
  journal  = "IEEE Trans. Comput. Intell. AI Games",
  volume   =  6,
  number   =  4,
  pages    = "382--394",
  month    =  dec,
  year     =  2014,
  keywords = "Monte Carlo methods;computer games;genetic algorithms;trees
              (mathematics);EvoMCTS approach;MCTS playout strategy;Monte Carlo
              tree search;board-state evaluation functions;domain
              knowledge;general game learning approach;genetic
              programming;selective directional crossover
              method;Abstracts;Algorithm design and analysis;Databases;Game
              theory;Games;Genetic programming;Monte Carlo methods;Board
              games;Monte Carlo methods;genetic programming;search"
}

@TECHREPORT{Doherty2006-yz,
  title       = "The Design Goals and Implementation of {AI} in Modern Computer
                 Games",
  author      = "Doherty, Darren and O'Riordan, Colm",
  institution = "Technical report. 17",
  year        =  2006
}


@ARTICLE{Yeh2016-ts,
  title    = "Snake Game {AI}: Movement Rating Functions and Evolutionary
              Algorithm-based Optimization",
  author   = "Yeh, J F and Su, P H and Huang, S H and Chiang, T C",
  abstract = "Abstract---Snake game is a computer action game, whose goal is to
              control a snake to move and collect food in a map. In this paper
              we develop a controller based on movement rating functions
              considering smoothness, space, and food. Scores given by these
              functions are",
  journal  = "researchgate.net",
  month    =  "11~" # jan,
  year     =  2016
}

@INPROCEEDINGS{Cole2004-ip,
  title     = "Using a genetic algorithm to tune first-person shooter bots",
  booktitle = "Evolutionary Computation, 2004. {CEC2004}. Congress on",
  author    = "Cole, N and Louis, S J and Miles, C",
  abstract  = "Using a genetic algorithm to tune first-person shooter bots on
               ResearchGate, the professional network for scientists.",
  volume    =  1,
  pages     = "139--145 Vol.1",
  month     =  "19~" # jul,
  year      =  2004
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Doherty2008-ml,
  title     = "Evolving team behaviours in environments of varying difficulty",
  author    = "Doherty, Darren and O’Riordan, Colm",
  abstract  = "This paper investigates how varying the difficulty of the
               environment can affect the evolution of team behaviour in a
               combative game setting. The difficulty of the environment is
               altered by varying the perceptual capabilities of the agents in
               the game. The behaviours of the agents are evolved using a
               genetic program. These experiments show that the level of
               difficulty of the environment does have an impact on the
               evolvability of effective team behaviours; i.e. simpler
               environments are more conducive to the evolution of effective
               team behaviours than more difficult environments. In addition,
               the experiments show that no one best solution from any
               environment is optimal for all environments.",
  journal   = "Artif Intell Rev",
  publisher = "Springer Netherlands",
  volume    =  27,
  number    =  4,
  pages     = "223--244",
  month     =  "13~" # sep,
  year      =  2008,
  language  = "en"
}

@ARTICLE{Benbassat2014-sj,
  title    = "{EvoMCTS}: A Scalable Approach for General Game Learning",
  author   = "Benbassat, A and Sipper, M",
  abstract = "In this paper, we present the application of genetic programming
              as a generic game learning approach to zero-sum, deterministic,
              full-knowledge board games by evolving board-state evaluation
              functions to be used in conjunction with Monte Carlo tree search
              (MCTS). Our method involves evolving board-evaluation functions
              that are then used to guide the MCTS playout strategy. We examine
              several variants of Reversi, Dodgem, and Hex using strongly typed
              genetic programming, explicitly defined introns, and a selective
              directional crossover method. Our results show a proficiency that
              surpasses that of baseline handcrafted players using equal and in
              some cases greater amounts of search, with little domain
              knowledge and no expert domain knowledge. Moreover, our results
              exhibit scalability.",
  journal  = "IEEE Trans. Comput. Intell. AI Games",
  volume   =  6,
  number   =  4,
  pages    = "382--394",
  month    =  dec,
  year     =  2014,
  keywords = "Monte Carlo methods;computer games;genetic algorithms;trees
              (mathematics);EvoMCTS approach;MCTS playout strategy;Monte Carlo
              tree search;board-state evaluation functions;domain
              knowledge;general game learning approach;genetic
              programming;selective directional crossover
              method;Abstracts;Algorithm design and analysis;Databases;Game
              theory;Games;Genetic programming;Monte Carlo methods;Board
              games;Monte Carlo methods;genetic programming;search"
}

@INPROCEEDINGS{Singh2014-yz,
  title     = "A {\#x0022;Never-Loose} \#x0022; Strategy to Play the Game of
               {Tic-Tac-Toe}",
  booktitle = "2014 International Conference on Soft Computing and Machine
               Intelligence",
  author    = "Singh, A and Deep, K and Nagar, A",
  abstract  = "In much of the literature available to solve the tic-tac-toe
               board game, the common approaches, such as, co evolution, neural
               networks, evolutionary programming and genetic algorithm are
               used. In the present work we present a deterministic approach
               for playing tic-tac-toe game, in which 9 objective functions are
               defined to decide player's best move. For choosing the best from
               the solutions generated, by combination of mutating zero as 1,
               certain axioms are defined. The beauty of this method lies in
               the fact that if the player decides a move with this method, he
               never loses the match whenever the player begins the game. We
               suspect that functions can be defined on the similar grounds for
               other existing board games and some of this work is in progress
               and will be reported elsewhere. Some implications on these lines
               have been made as recommendations in this paper.",
  pages     = "1--5",
  year      =  2014,
  keywords  = "computer games;genetic algorithms;neural
               nets;coevolution;deterministic approach;evolutionary
               programming;genetic algorithm;neural network;never-loose
               strategy;tic-tac-toe board game;Algorithm design and
               analysis;Games;Genetic algorithms;Linear
               programming;Mathematical model;Neural
               networks;Programming;Tic-tac-toe;game;multi-objective"
}




@INPROCEEDINGS{Leong2013-pu,
  title     = "Self-synthesized controllers for tower defense game using
               genetic programming",
  booktitle = "2013 {IEEE} International Conference on Control System,
               Computing and Engineering",
  author    = "Leong, L C and Soon, G K and Guan, T T and On, C K and Alfred, R
               and Anthony, P",
  abstract  = "In this paper, we describe the results of implementing Genetic
               Programming (GP) using two different Artificial Neural Networks
               (ANN) topologies in a customized Tower Defense (TD) games. The
               ANNs used are (1) Feed-forward Neural Network (FFNN) and (2)
               Elman-Recurrent Neural Network (ERNN). TD game is one of the
               strategy game genres. Players are required to build towers in
               order to prevent the creeps from reaching their bases. Lives
               will be deducted if any creeps manage to reach the base. In this
               research, a map will be designed. The AI method used will
               self-synthesize and analyze the level of difficulty of the
               designed map. The GP acts as a tuner of the weights in ANNs. The
               ANNs will act as players to block the creeps from reaching the
               base. The map will then be evaluated by the ANNs in the testing
               phase. Our findings showed that GP works well with ERNN compared
               to GP with FFNN.",
  pages     = "487--492",
  month     =  nov,
  year      =  2013,
  keywords  = "artificial intelligence;computer games;control engineering
               computing;feedforward neural nets;genetic algorithms;recurrent
               neural nets;AI method;ANN topologies;ERNN;Elman-recurrent neural
               network;FFNN;artificial neural networks;feedforward neural
               network;genetic programming;self-synthesized controllers;tower
               defense game;Artificial intelligence;Artificial neural
               networks;Biological cells;Creep;Games;Neurons;Poles and
               towers;Artificial Neural Network (ANN);Elman-Recurrent Neural
               Network (ERNN);Feed-forward Neural Network (FFNN);Genetic
               Programming (GP);Tower Defense (TD) Game"
}


@PHDTHESIS{Christopher_Lockhart2010-em,
  title    = "Application of temporal difference learning to the game of Snake",
  author   = "Christopher Lockhart, University of Louisville and {Authors}",
  abstract = "The game of Snake has been selected to provide a unique
              application of the TD( ) algorithm as proposed by Sutton. A
              reinforcement learning technique for producing computer
              controlled players is documented. Using value function
              approximation with multilayer artificial neural networks and the
              actor-critic architecture, computer players capable of playing
              the game of Snake can be created. The adaptation to the standard
              neural network backpropagation procedure will be documented. Not
              only does the proposed technique provide reasonable player
              performance, its application is unique; this approach to Snake
              has never been documented. By performing sets of trials, the
              performance of the players are evaluated and compared against an
              existing machine learning technique. Learning curves provide
              visualization for the results. Though the snake players are shown
              to be capable of achieving lower scores than with the existing
              method, the technique is able to produce agents that accumulate
              scores, much more efficiently.",
  year     =  2010,
  school   = "University of Louisville"
}




@ARTICLE{Bowei_Ma_undated-tl,
  title    = "Exploration of Reinforcement Learning to {SNAKE}",
  author   = "Bowei Ma, Meng Tang",
  abstract = "In this project, we explored the application of reinforcement
              learning in the problem not amenable to closed form analysis. By
              combining convolutional neural network and reinforcement
              learning, an agent of game Snake is trained to play the revised
              Snake game. The challenge is that the size of state space is
              extremely huge due to the fact that position of the snake affects
              the training results directly while its changing all the time. By
              training the agent in a reduced state space, we showed the
              comparisons among different reinforcement learning algorithms and
              approximation optimal solution, and analyzed the difference
              between two major reinforcement learning method."
}


@ARTICLE{Whitley1994-tx,
  title     = "A genetic algorithm tutorial",
  author    = "Whitley, Darrell",
  abstract  = "This tutorial covers the canonical genetic algorithm as well as
               more experimental forms of genetic algorithms, including
               parallel island models and parallel cellular genetic algorithms.
               The tutorial a",
  journal   = "Stat. Comput.",
  publisher = "Kluwer Academic Publishers",
  volume    =  4,
  number    =  2,
  pages     = "65--85",
  month     =  "1~" # jun,
  year      =  1994,
  language  = "en"
}


@MISC{Ashlock_undated-vx,
  title        = "Evolutionary Computation for Modeling and Optimization by
                  Ashlock, Daniel: Springer 9780387221960 Hardcover - Motor
                  City Books",
  author       = "Ashlock, Daniel",
  abstract     = "AbeBooks.com: Evolutionary Computation for Modeling and
                  Optimization",
  publisher    = "Springer",
  howpublished = "\url{https://www.abebooks.com/servlet/BookDetailsPL?bi=19887295686&searchurl=isbn%3D0387221964%26sortby%3D17}",
  note         = "Accessed: 2017-1-20",
  year         = 2006
}


@INPROCEEDINGS{Wloch2004-vo,
  title      = "Optimising the Performance of a Formula One Car Using a Genetic
                Algorithm",
  booktitle  = "Parallel Problem Solving from Nature - {PPSN} {VIII}",
  author     = "Wloch, Krzysztof and Bentley, Peter J",
  editor     = "Yao, Xin and Burke, Edmund K and Lozano, Jos{\'e} A and Smith,
                Jim and Merelo-Guerv{\'o}s, Juan Juli{\'a}n and Bullinaria,
                John A and Rowe, Jonathan E and Ti{\v n}o, Peter and Kab{\'a}n,
                Ata and Schwefel, Hans-Paul",
  abstract   = "Formula One motor racing is a rich sport that spends millions
                on research and development of highly optimized cars. Here we
                describe the use of a genetic algorithm to optimize 66 setup
                parameters for a simulation of a Formula One car and
                demonstrate performance improvements (faster lap times) better
                than all other methods tested.",
  publisher  = "Springer Berlin Heidelberg",
  pages      = "702--711",
  series     = "Lecture Notes in Computer Science",
  month      =  "18~" # sep,
  year       =  2004,
  language   = "en",
  conference = "International Conference on Parallel Problem Solving from
                Nature"
}

